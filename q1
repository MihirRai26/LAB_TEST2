from sklearn.datasets import load_wine
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
data = load_wine()
df = pd.DataFrame(data.data, columns=data.feature_names)
df['target'] = data.target
print("1st 10 rows of the dataset are:\n", df.head(10))
print("\ndataset summary:")
print("no of samples:", df.shape[0])
print("no of features:", df.shape[1] - 1)  
print("no of classes:", len(np.unique(df['target'])))
x_train, x_test, y_train, y_test = train_test_split(df[data.feature_names], df['target'], test_size=0.3, random_state=42)
scaler=StandardScaler()
x_train_scaled=scaler.fit_transform(x_train)
x_test_scaled=scaler.transform(x_test)
pd.DataFrame(X_train_scaled, columns=X_train.columns).hist(ax=axes[1], bins=15)
axes[1].set_title("Feature Distribution After Scaling")
plt.tight_layout()
plt.show()
clf = DecisionTreeClassifier(random_state=42)
clf = DecisionTreeClassifier(random_state=42)
param_grid = {
    'max_depth': [3, 5, 7, 10],
    'min_samples_split': [2, 5, 10]
}
grid_search = GridSearchCV(clf, param_grid, cv=5)
grid_search.fit(X_train_scaled, y_train)

print("\nbest hyperparameters:", grid_search.best_params_)
best_clf = grid_search.best_estimator_
y_pred = best_clf.predict(X_test_scaled)
print("\nmodel evaluation:")
print("accuracy:", accuracy_score(y_test, y_pred))
print("precision:", precision_score(y_test, y_pred, average='weighted'))
print("recall:", recall_score(y_test, y_pred, average='weighted'))
print("f1 score:", f1_score(y_test, y_pred, average='weighted'))
conf_matrix = confusion_matrix(y_test, y_pred)
print("\nConfusion Matrix:\n", conf_matrix)
